model_list:
  # Модель 1: GPT-OSS-120B через Groq
  - model_name: gpt-oss-120b
    litellm_params:
      model: groq/openai/gpt-oss-120b
      api_base: https://api.groq.com/openai/v1
      api_key: os.environ/GROQ_API_KEY
      temperature: 0.1
      max_tokens: 10000
      timeout: 30
      rpm: 30
      tpm: 6000
    model_info:
      id: gpt-oss-120b
      mode: chat
      supports_function_calling: true
      supports_vision: false
      max_requests_per_minute: 30
      max_tokens_per_minute: 6000
      max_requests_per_day: 1000

  # Модель 2: Deepseek через OpenRouter
  - model_name: deepseek-chat
    litellm_params:
      model: openrouter/deepseek/deepseek-chat-v3.1:free
      api_base: https://openrouter.ai/api/v1
      api_key: os.environ/OPENROUTER_API_KEY
      temperature: 0.1
      max_tokens: 10000
      timeout: 30
      rpm: 20
    model_info:
      id: deepseek-chat
      mode: chat
      supports_function_calling: true
      supports_vision: false
      max_requests_per_minute: 20
      max_requests_per_day: 50

  # Модель 3: Gemini Flash Lite
  - model_name: gemini-flash-lite
    litellm_params:
      model: gemini/gemini-flash-lite-latest
      api_key: os.environ/GEMINI_API_KEY
      temperature: 0.1
      max_tokens: 8000
      timeout: 30
      rpm: 15
      tpm: 1000000
    model_info:
      id: gemini-flash-lite
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_requests_per_minute: 15
      max_tokens_per_minute: 1000000
      max_requests_per_day: 1500

  # Модель 4: Gemini Flash
  - model_name: gemini-flash
    litellm_params:
      model: gemini/gemini-flash-latest
      api_key: os.environ/GEMINI_API_KEY
      temperature: 0.1
      max_tokens: 8000
      timeout: 30
      rpm: 15
      tpm: 1000000
    model_info:
      id: gemini-flash
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_requests_per_minute: 15
      max_tokens_per_minute: 1000000
      max_requests_per_day: 1500

  # Модель 5: Gemini 2.5 Pro
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: os.environ/GEMINI_API_KEY
      temperature: 0.1
      max_tokens: 8000
      timeout: 30
      rpm: 10
      tpm: 4000000
    model_info:
      id: gemini-2.5-pro
      mode: chat
      supports_function_calling: true
      supports_vision: true
      max_requests_per_minute: 10
      max_tokens_per_minute: 4000000
      max_requests_per_day: 1500

  # Группа моделей для распределения нагрузки
  - model_name: chat-models
    litellm_params:
      model: groq/openai/gpt-oss-120b
      api_base: https://api.groq.com/openai/v1
      api_key: os.environ/GROQ_API_KEY
      rpm: 30
      tpm: 6000
    model_info:
      id: chat-models-groq
      mode: chat

  - model_name: chat-models
    litellm_params:
      model: openrouter/deepseek/deepseek-chat-v3.1:free
      api_base: https://openrouter.ai/api/v1
      api_key: os.environ/OPENROUTER_API_KEY
      rpm: 20
    model_info:
      id: chat-models-openrouter
      mode: chat

  - model_name: chat-models
    litellm_params:
      model: gemini/gemini-flash-lite-latest
      api_key: os.environ/GEMINI_API_KEY
      rpm: 15
      tpm: 1000000
    model_info:
      id: chat-models-gemini
      mode: chat

  - model_name: chat-models
    litellm_params:
      model: gemini/gemini-flash-lite-latest
      api_key: os.environ/GEMINI_API_KEY
      temperature: 0.1
      max_tokens: 8000
      timeout: 30
      rpm: 15
      tpm: 1000000
    model_info:
      id: gemini-flash-lite
      mode: chat

# Общие настройки
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  set_verbose: true
  json_logs: true

  # Кэширование
  cache: true
  cache_params:
    type: redis
    host: redis
    port: 6379

  # Бюджеты и лимиты
  max_budget: 100
  budget_duration: 30d

  # Rate Limiting
  enable_rate_limit: true

# Настройки роутера
router_settings:
  routing_strategy: simple-shuffle  # Случайный выбор между моделями
  # Можно также использовать:
  # routing_strategy: least-busy  # Выбор наименее загруженной
  # routing_strategy: latency-based-routing  # На основе latency

# Настройки успеха/неудачи
litellm_settings:
  success_callback: []
  failure_callback: []
  num_retries: 3
  request_timeout: 600
  stream_response: true

  # Fallback между моделями
  fallbacks: [{"chat-models": ["gpt-oss-120b", "deepseek-chat", "gemini-flash"]}]